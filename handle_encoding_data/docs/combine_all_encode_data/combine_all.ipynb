{
 "cells": [
  {
   "cell_type": "code",
   "id": "8nxlhlzo825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T02:02:29.824557Z",
     "start_time": "2025-10-06T02:02:29.822107Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "osgwdhd37v",
   "metadata": {},
   "source": [
    "## Load All Encoded Datasets\n",
    "\n",
    "Load each encoded dataset to extract the new encoded columns:"
   ]
  },
  {
   "cell_type": "code",
   "id": "v9cz6d4eldb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T02:02:31.713952Z",
     "start_time": "2025-10-06T02:02:31.639244Z"
    }
   },
   "source": [
    "# Define input paths\n",
    "BASE_PATH = \"../../output_data\"\n",
    "OUTPUT_PATH = \"../../output_data/final_encoded_data/final_fully_encoded_dataset.csv\"\n",
    "\n",
    "# Load all encoded datasets\n",
    "df_customer = pd.read_csv(f\"{BASE_PATH}/1_customer_id/encoded_customer_id_dataset.csv\")\n",
    "df_location = pd.read_csv(f\"{BASE_PATH}/2_location/location_binary_encoded.csv\")\n",
    "df_payment = pd.read_csv(f\"{BASE_PATH}/3_payment_method/encoded_payment_method_dataset.csv\")\n",
    "df_discount = pd.read_csv(f\"{BASE_PATH}/4_discount_applied/discount_applied_one_hot_encoded.csv\")\n",
    "df_category = pd.read_csv(f\"{BASE_PATH}/5_category/encoded_category_dataset.csv\")\n",
    "df_item = pd.read_csv(f\"{BASE_PATH}/6_item/encoded_item_dataset.csv\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "4bwq66rnz53",
   "metadata": {},
   "source": [
    "## Merge Encoded Columns\n",
    "\n",
    "Merge all encoded columns based on Transaction ID:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ck2n96bemoh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T02:02:33.497582Z",
     "start_time": "2025-10-06T02:02:33.489909Z"
    }
   },
   "source": "# Start with category dataset (has the most accumulated columns from previous steps)\nfinal_df = df_category.copy()\n\n# Add Customer ID Target Encoding\nfinal_df['Customer ID Target Encoded'] = df_customer['Customer ID Target Encoded']\n\n# Add Item Target Encoding\nfinal_df['Item Target Encoded'] = df_item['Item Target Encoded']\n\n# Add Location encoding\nfinal_df['Location_Encoded'] = df_location['Location_Encoded']\n\n# Add Payment Method encodings\nfinal_df['Payment_Cash'] = df_payment['Payment_Cash']\nfinal_df['Payment_Credit Card'] = df_payment['Payment_Credit Card']\nfinal_df['Payment_Digital Wallet'] = df_payment['Payment_Digital Wallet']\n\n# Add Discount Applied encodings\nfinal_df['Discount_False'] = df_discount['Discount_False']\nfinal_df['Discount_True'] = df_discount['Discount_True']\nfinal_df['Discount_Unknown'] = df_discount['Discount_Unknown']\n\nprint(f\"\\nCombined dataset shape: {final_df.shape}\")\nprint(f\"Column count: {len(final_df.columns)}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined dataset shape: (11971, 28)\n",
      "Column count: 28\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "l519pil9cre",
   "metadata": {},
   "source": [
    "## Drop Original Categorical Columns\n",
    "\n",
    "Remove original categorical columns, keeping only numerical and encoded features:"
   ]
  },
  {
   "cell_type": "code",
   "id": "50chtuirifm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T02:02:35.794736Z",
     "start_time": "2025-10-06T02:02:35.788468Z"
    }
   },
   "source": [
    "# Columns to drop (original categorical)\n",
    "columns_to_drop = ['Customer ID', 'Category', 'Item', 'Payment Method', 'Location', 'Discount Applied']\n",
    "\n",
    "# Drop original categorical columns\n",
    "final_df = final_df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"After dropping original categorical columns:\")\n",
    "print(f\"Shape: {final_df.shape}\")\n",
    "print(f\"\\nRemaining columns ({len(final_df.columns)}):\")\n",
    "print(final_df.columns.tolist())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping original categorical columns:\n",
      "Shape: (11971, 22)\n",
      "\n",
      "Remaining columns (22):\n",
      "['Transaction ID', 'Price Per Unit', 'Quantity', 'Total Spent', 'Transaction Date', 'cat_Beverages', 'cat_Butchers', 'cat_Computers and electric accessories', 'cat_Electric household essentials', 'cat_Food', 'cat_Furniture', 'cat_Milk Products', 'cat_Patisserie', 'Customer ID Target Encoded', 'Item Target Encoded', 'Location_Encoded', 'Payment_Cash', 'Payment_Credit Card', 'Payment_Digital Wallet', 'Discount_False', 'Discount_True', 'Discount_Unknown']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "o41dfz2gak",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Verify the final encoded dataset:"
   ]
  },
  {
   "cell_type": "code",
   "id": "by55lbtlwi5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T02:02:37.981838Z",
     "start_time": "2025-10-06T02:02:37.968698Z"
    }
   },
   "source": [
    "# 1. No missing values in encoded columns\n",
    "encoded_cols = [col for col in final_df.columns if col not in ['Transaction ID', 'Price Per Unit', 'Quantity', 'Total Spent', 'Transaction Date']]\n",
    "no_missing = final_df[encoded_cols].isna().sum().sum() == 0\n",
    "print(f\"1. No missing values in encoded columns: {no_missing}\")\n",
    "\n",
    "# 2. One-hot columns sum to 1 per row (Payment Method)\n",
    "payment_cols = ['Payment_Cash', 'Payment_Credit Card', 'Payment_Digital Wallet']\n",
    "payment_sum_check = (final_df[payment_cols].sum(axis=1) == 1).all()\n",
    "print(f\"2. Payment Method one-hot sums to 1 per row: {payment_sum_check}\")\n",
    "\n",
    "# 3. One-hot columns sum to 1 per row (Discount Applied)\n",
    "discount_cols = ['Discount_False', 'Discount_True', 'Discount_Unknown']\n",
    "discount_sum_check = (final_df[discount_cols].sum(axis=1) == 1).all()\n",
    "print(f\"3. Discount Applied one-hot sums to 1 per row: {discount_sum_check}\")\n",
    "\n",
    "# 4. Category one-hot columns sum to 1 per row\n",
    "category_cols = [col for col in final_df.columns if col.startswith('cat_')]\n",
    "category_sum_check = (final_df[category_cols].sum(axis=1) == 1).all()\n",
    "print(f\"4. Category one-hot sums to 1 per row: {category_sum_check}\")\n",
    "\n",
    "# 5. Binary encoding has only 0/1\n",
    "binary_check = final_df['Location_Encoded'].isin([0, 1]).all()\n",
    "print(f\"5. Location encoding contains only 0/1: {binary_check}\")\n",
    "\n",
    "# 6. Row count preserved\n",
    "print(f\"6. Row count: {len(final_df)} (expected: 11,971)\")\n",
    "\n",
    "# 7. Column count check\n",
    "print(f\"\\n7. Final column breakdown:\")\n",
    "print(f\"   - Identifiers: 1 (Transaction ID)\")\n",
    "print(f\"   - Numerical: 4 (Price Per Unit, Quantity, Total Spent, Transaction Date)\")\n",
    "print(f\"   - Customer ID encoding: 1\")\n",
    "print(f\"   - Item encoding: 1\")\n",
    "print(f\"   - Category encoding: {len(category_cols)}\")\n",
    "print(f\"   - Location encoding: 1\")\n",
    "print(f\"   - Payment encoding: 3\")\n",
    "print(f\"   - Discount encoding: 3\")\n",
    "print(f\"   - TOTAL: {len(final_df.columns)} columns\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. No missing values in encoded columns: True\n",
      "2. Payment Method one-hot sums to 1 per row: True\n",
      "3. Discount Applied one-hot sums to 1 per row: True\n",
      "4. Category one-hot sums to 1 per row: True\n",
      "5. Location encoding contains only 0/1: True\n",
      "6. Row count: 11971 (expected: 11,971)\n",
      "\n",
      "7. Final column breakdown:\n",
      "   - Identifiers: 1 (Transaction ID)\n",
      "   - Numerical: 4 (Price Per Unit, Quantity, Total Spent, Transaction Date)\n",
      "   - Customer ID encoding: 1\n",
      "   - Item encoding: 1\n",
      "   - Category encoding: 8\n",
      "   - Location encoding: 1\n",
      "   - Payment encoding: 3\n",
      "   - Discount encoding: 3\n",
      "   - TOTAL: 22 columns\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "6yo4zmy9e3",
   "metadata": {},
   "source": [
    "## Preview Final Dataset\n",
    "\n",
    "Display first few rows and summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "q057s7e8mb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T18:46:25.808605Z",
     "start_time": "2025-10-04T18:46:25.797928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction ID  Price Per Unit  Quantity  Total Spent Transaction Date  \\\n",
      "0    TXN_1002182            11.0       5.0         55.0       2024-10-08   \n",
      "1    TXN_1003865             6.5       5.0         32.5       2022-03-12   \n",
      "2    TXN_1003940            11.0       9.0         99.0       2022-04-22   \n",
      "3    TXN_1004091            41.0       3.0        123.0       2023-11-09   \n",
      "4    TXN_1004124            14.0       5.0         70.0       2022-03-02   \n",
      "\n",
      "   cat_Beverages  cat_Butchers  cat_Computers and electric accessories  \\\n",
      "0              0             0                                       0   \n",
      "1              0             0                                       0   \n",
      "2              0             0                                       0   \n",
      "3              0             0                                       0   \n",
      "4              0             0                                       1   \n",
      "\n",
      "   cat_Electric household essentials  cat_Food  cat_Furniture  \\\n",
      "0                                  0         1              0   \n",
      "1                                  0         0              1   \n",
      "2                                  0         0              1   \n",
      "3                                  0         1              0   \n",
      "4                                  0         0              0   \n",
      "\n",
      "   cat_Milk Products  cat_Patisserie  Location_Encoded  Payment_Cash  \\\n",
      "0                  0               0                 0         False   \n",
      "1                  0               0                 1          True   \n",
      "2                  0               0                 1         False   \n",
      "3                  0               0                 0          True   \n",
      "4                  0               0                 0         False   \n",
      "\n",
      "   Payment_Credit Card  Payment_Digital Wallet  Discount_False  Discount_True  \\\n",
      "0                False                    True           False           True   \n",
      "1                False                   False            True          False   \n",
      "2                False                    True            True          False   \n",
      "3                False                   False            True          False   \n",
      "4                 True                   False           False          False   \n",
      "\n",
      "   Discount_Unknown  \n",
      "0             False  \n",
      "1             False  \n",
      "2             False  \n",
      "3             False  \n",
      "4              True  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed3mphpr6",
   "metadata": {},
   "source": [
    "## Save Final Encoded Dataset\n",
    "\n",
    "Save the fully encoded dataset to output directory:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ig894qv5xjq",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T02:02:41.632351Z",
     "start_time": "2025-10-06T02:02:41.577402Z"
    }
   },
   "source": [
    "# Create output directory if it doesn't exist\n",
    "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the final encoded dataset\n",
    "final_df.to_csv(OUTPUT_PATH, index=False)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83831ad854449af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
