{
 "cells": [
  {
   "cell_type": "code",
   "id": "1f353abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:38.004613Z",
     "start_time": "2025-10-06T19:56:37.999069Z"
    }
   },
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "3ba4b846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:38.426516Z",
     "start_time": "2025-10-06T19:56:38.422736Z"
    }
   },
   "source": "# Input dataset\nCSV_IN = \"../../datasource/Deliverable1Dataset.csv\"\nCSV_OUT = \"../../output/1_handle_missing_data/total_spent_cleaned.csv\"\n# Define columns name\nTOTAL_SPENT = \"Total Spent\"\nPRICE_PER_UNIT = \"Price Per Unit\"\nQUANTITY = \"Quantity\"\nCATEGORY = \"Category\"\nPAYMENT_METHOD = \"Payment Method\"\nLOCATION = \"Location\"\nITEM = \"Item\"\nTRANSACTION_ID = \"Transaction ID\"\n\n# Define error\nCOERCE_ERRORS = \"coerce\"",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "01609558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:38.998939Z",
     "start_time": "2025-10-06T19:56:38.976414Z"
    }
   },
   "source": [
    "df = pd.read_csv(CSV_IN)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "f2228ca8",
   "metadata": {},
   "source": [
    "### Determine missingness of Total Spent\n",
    "\n",
    "Before checking, convert all the existing data types (string) to appropriate numeric type for comparison the relationship since `Price Per Unit`, `Quantity` and `Total Spent` are related. Check to see how many missing observations for `Total Spent`\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:40.002890Z",
     "start_time": "2025-10-06T19:56:39.997651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert column's values to numeric, coercing errors to NaN\n",
    "# col is each of the relevant columns\n",
    "for col in [PRICE_PER_UNIT, QUANTITY, TOTAL_SPENT]:\n",
    "    # pd.to_numeric converts values in col to numeric, with errors coerced to NaN\n",
    "    # df[col] accesses the target column\n",
    "    # errors=COERCE_ERRORS specifies that parsing errors are set to NaN\n",
    "    df[col] = pd.to_numeric(df[col], errors=COERCE_ERRORS)\n",
    "\n",
    "\n",
    "totalRow = len(df)\n",
    "\n",
    "missingValue = df[TOTAL_SPENT].isna().sum()\n",
    "# missingPercent is the percentage of rows where TOTAL_SPENT is NaN\n",
    "# missingValue / totalRow computes the fraction of missing values\n",
    "missingPercent = round(missingValue / totalRow * 100, 2)\n",
    "\n",
    "print(f\"Total rows: {totalRow}\")\n",
    "print(f\"Missing {TOTAL_SPENT}: {missingValue} ({missingPercent}%)\")"
   ],
   "id": "fb10c90d3a25e8ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 12575\n",
      "Missing Total Spent: 604 (4.8%)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "c0e6ec84",
   "metadata": {},
   "source": [
    "### Missingness mechanism\n",
    "\n",
    "Quantifying how often `Total Spent` is missing within each `Category`, `payment method`, and `location` to see their relationships with Total Spent if they were depended on or related to each other. From that can conclude what kind of missing data type like Missing Completely At Random (MCAR), Missing At Random (MAR), or Missing Not At Random (MNAR) and propose the appropriate approach to handle\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:41.036540Z",
     "start_time": "2025-10-06T19:56:41.028366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Missingness by Category\n",
    "byCategory = df.groupby(CATEGORY)[TOTAL_SPENT].apply(lambda x: x.isna().mean()).sort_values(ascending=False) * 100\n",
    "print(\"\\nMissing Total Spent by Category (%):\")\n",
    "print(byCategory.round(2))\n",
    "\n",
    "# Missingness by Payment Method\n",
    "byPayment = df.groupby(PAYMENT_METHOD)[TOTAL_SPENT].apply(lambda x: x.isna().mean()).sort_values(ascending=False) * 100\n",
    "print(\"\\nMissing Total Spent by Payment Method (%):\")\n",
    "print(byPayment.round(2))\n",
    "\n",
    "# Missingness by Location\n",
    "byLocation = df.groupby(LOCATION)[TOTAL_SPENT].apply(lambda x: x.isna().mean()).sort_values(ascending=False) * 100\n",
    "print(\"\\nMissing Total Spent by Location (%):\")\n",
    "print(byLocation.round(2))\n"
   ],
   "id": "ec9ed2339ff7cd02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Total Spent by Category (%):\n",
      "Category\n",
      "Patisserie                            5.69\n",
      "Computers and electric accessories    5.20\n",
      "Food                                  5.10\n",
      "Electric household essentials         4.71\n",
      "Butchers                              4.59\n",
      "Beverages                             4.53\n",
      "Milk Products                         4.48\n",
      "Furniture                             4.15\n",
      "Name: Total Spent, dtype: float64\n",
      "\n",
      "Missing Total Spent by Payment Method (%):\n",
      "Payment Method\n",
      "Digital Wallet    4.90\n",
      "Cash              4.80\n",
      "Credit Card       4.71\n",
      "Name: Total Spent, dtype: float64\n",
      "\n",
      "Missing Total Spent by Location (%):\n",
      "Location\n",
      "In-store    5.11\n",
      "Online      4.50\n",
      "Name: Total Spent, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "9c47aae4",
   "metadata": {},
   "source": [
    "### Co-missingness analysis\n",
    "\n",
    "Examining whether `Total Spent` is missing alongside other key fields which determine the appropriate patterns. \n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:41.965205Z",
     "start_time": "2025-10-06T19:56:41.961835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# related missingness with Quantity\n",
    "relateMissingQty = ((df[TOTAL_SPENT].isna()) & (df[QUANTITY].isna())).sum()\n",
    "\n",
    "print(f'Rows with both Total Spent and Quantity missing: {relateMissingQty}')\n",
    "print(f'Total Spent missing: {missingValue}')\n",
    "print(f'Perfect overlap: {relateMissingQty == missingValue}')\n",
    "\n",
    "# Check co-missingness with Price Per Unit\n",
    "relateMissingPrice = ((df[TOTAL_SPENT].isna()) & (df[PRICE_PER_UNIT].isna())).sum()\n",
    "print(f'\\nRows with both Total Spent and Price Per Unit missing: {relateMissingPrice}')\n",
    "\n",
    "# Check co-missingness with Item\n",
    "relatedMissingItem = ((df[TOTAL_SPENT].isna()) & (df[ITEM].isna())).sum()\n",
    "print(f'Rows with both Total Spent and Item missing: {relatedMissingItem}')\n",
    "print(f'Percentage of Total Spent missing cases with Item also missing: {relatedMissingItem / missingValue * 100:.2f}%')\n"
   ],
   "id": "2e9ace45431e7dff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with both Total Spent and Quantity missing: 604\n",
      "Total Spent missing: 604\n",
      "Perfect overlap: True\n",
      "\n",
      "Rows with both Total Spent and Price Per Unit missing: 0\n",
      "Rows with both Total Spent and Item missing: 604\n",
      "Percentage of Total Spent missing cases with Item also missing: 100.00%\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "97e48072",
   "metadata": {},
   "source": [
    "### Reconstructability assessment\n",
    "\n",
    "Since `Total Spent = Price Per Unit × Quantity`, we assess how many missing `Total Spent` values could theoretically be reconstructed from the other two fields. This determines whether imputation is feasible or deletion is necessary.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:42.806159Z",
     "start_time": "2025-10-06T19:56:42.803168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if Total Spent can be reconstructed from Price Per Unit and Quantity\n",
    "# For reconstruction, we need Total Spent to be missing BUT both Price and Quantity to be present\n",
    "reconstructable = df[TOTAL_SPENT].isna() & df[PRICE_PER_UNIT].notna() & df[QUANTITY].notna()\n",
    "reconstructableCount = reconstructable.sum()\n",
    "\n",
    "print(f'Missing Total Spent that CAN be reconstructed: {reconstructableCount} out of {missingValue}')\n",
    "print(f'Reconstruction rate: {reconstructableCount / missingValue:.1%}')\n"
   ],
   "id": "ed7eefd0a9fd22ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Total Spent that CAN be reconstructed: 0 out of 604\n",
      "Reconstruction rate: 0.0%\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "40b65276",
   "metadata": {},
   "source": [
    "### Missing data classification\n",
    "\n",
    "**Classification: MAR (Missing At Random)**\n",
    "\n",
    "**Rationale:**\n",
    "- Perfect co-missingness with `Quantity` (604 cases = 100% overlap)\n",
    "- Missing rates vary by category (4.15%-5.69%), indicating dependence on observable characteristics\n",
    "- Strongly correlated with `Item` field missingness (100% of cases have Item also missing)\n",
    "- The missingness is systematic and related to the Item field (an observable variable)\n",
    "- Not MCAR because missing rates are not uniform across categories\n",
    "- Not MNAR because the missingness is explained by observable variables (Item field status)\n",
    "\n",
    "**Key finding:** When `Item` was not recorded during data collection, both `Quantity` and `Total Spent` were also systematically omitted, suggesting a data entry workflow issue rather than values being hidden due to their magnitude.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25116ba7",
   "metadata": {},
   "source": [
    "### Handling strategy: Listwise deletion\n",
    "\n",
    "**Justification for deletion (not imputation):**\n",
    "\n",
    "1. **Critical target variable:** `Total Spent` is essential for transaction analysis and should not be estimated\n",
    "2. **Perfect co-missingness:** These 604 rows also have missing `Quantity`, making reconstruction impossible\n",
    "3. **Cannot reliably impute:** Missing both Quantity AND at least one other key field\n",
    "4. **Small data loss:** Only 4.8% of the dataset vs. large gain in data integrity\n",
    "5. **Side benefit:** Eliminates 604 problematic cases that would require multiple imputations\n",
    "\n",
    "**Alternative considered:** Reconstruct using Price × Quantity\n",
    "- Not feasible: 0% of missing Total Spent cases have both Price and Quantity present\n",
    "- Would require imputing Quantity first, introducing estimation error into a critical field\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:44.132226Z",
     "start_time": "2025-10-06T19:56:44.124679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Use mask to filter rows, then select columns\n",
    "print(df[df[TOTAL_SPENT].isna()][[TRANSACTION_ID, CATEGORY, ITEM, PRICE_PER_UNIT, QUANTITY, TOTAL_SPENT]].head(10))\n"
   ],
   "id": "7139276d4df110b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Transaction ID                            Category Item  Price Per Unit  \\\n",
      "6      TXN_1005543                                Food  NaN            30.5   \n",
      "64     TXN_1041483       Electric household essentials  NaN            15.5   \n",
      "65     TXN_1041890                           Furniture  NaN            27.5   \n",
      "104    TXN_1069238                                Food  NaN             5.0   \n",
      "180    TXN_1130015                       Milk Products  NaN             9.5   \n",
      "216    TXN_1153995       Electric household essentials  NaN            23.0   \n",
      "217    TXN_1154680                           Furniture  NaN            35.0   \n",
      "225    TXN_1158381                            Butchers  NaN            36.5   \n",
      "249    TXN_1175914                            Butchers  NaN            23.0   \n",
      "262    TXN_1187836  Computers and electric accessories  NaN            38.0   \n",
      "\n",
      "     Quantity  Total Spent  \n",
      "6         NaN          NaN  \n",
      "64        NaN          NaN  \n",
      "65        NaN          NaN  \n",
      "104       NaN          NaN  \n",
      "180       NaN          NaN  \n",
      "216       NaN          NaN  \n",
      "217       NaN          NaN  \n",
      "225       NaN          NaN  \n",
      "249       NaN          NaN  \n",
      "262       NaN          NaN  \n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:44.999627Z",
     "start_time": "2025-10-06T19:56:44.992721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count rows before deletion\n",
    "rowsBefore = len(df)\n",
    "print(f'Rows before deletion: {rowsBefore}')\n",
    "print(f'Rows to be deleted: {missingValue}')\n",
    "\n",
    "# Perform listwise deletion\n",
    "dataCleaned = df.dropna(subset=[TOTAL_SPENT])\n",
    "\n",
    "# Count rows after deletion\n",
    "rowsAfter = len(dataCleaned)\n",
    "# Calculate retention rate as percentage\n",
    "retentionRate = (rowsAfter / rowsBefore) * 100\n",
    "\n",
    "print(f'\\nRows after deletion: {rowsAfter}')\n",
    "print(f'Rows deleted: {rowsBefore - rowsAfter}')\n"
   ],
   "id": "13c493a47198fd7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deletion: 12575\n",
      "Rows to be deleted: 604\n",
      "\n",
      "Rows after deletion: 11971\n",
      "Rows deleted: 604\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Validation: Side benefits of deletion\n",
    "\n",
    "Verify that deleting rows with missing `Total Spent` also eliminates other missing value problems, particularly with `Quantity`.\n"
   ],
   "id": "913a391aeb648aab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:46.726232Z",
     "start_time": "2025-10-06T19:56:46.720793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through critical numeric columns\n",
    "for col in [TOTAL_SPENT, QUANTITY, PRICE_PER_UNIT, ITEM]:\n",
    "    # dataCleaned[col].isna().sum() counts missing values in each column\n",
    "    missing_count = dataCleaned[col].isna().sum()\n",
    "    # Calculate percentage of missing values\n",
    "    missing_pct = (missing_count / len(dataCleaned)) * 100\n",
    "    # f-string formatting: {col:20s} pads column name to 20 characters for alignment\n",
    "    print(f'{col:20s}: {missing_count:5d} ({missing_pct:5.2f}%)')\n",
    "\n",
    "# Verify Total Spent is now complete\n",
    "print(f'\\n✓ Total Spent is now 100% complete: {dataCleaned[TOTAL_SPENT].isna().sum() == 0}')\n"
   ],
   "id": "83f502e61629324d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Spent         :     0 ( 0.00%)\n",
      "Quantity            :     0 ( 0.00%)\n",
      "Price Per Unit      :   609 ( 5.09%)\n",
      "Item                :   609 ( 5.09%)\n",
      "\n",
      "✓ Total Spent is now 100% complete: True\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Mathematical consistency check\n",
    "\n",
    "Verify that for all complete rows, the relationship `Total Spent = Price Per Unit × Quantity` holds true. This validates data quality and ensures no mathematical inconsistencies exist.\n"
   ],
   "id": "a4228bcd280a4bda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:48.099685Z",
     "start_time": "2025-10-06T19:56:48.093049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "completeRows = dataCleaned[[PRICE_PER_UNIT, QUANTITY, TOTAL_SPENT]].notna().all(axis=1)\n",
    "completeData = dataCleaned[completeRows].copy()\n",
    "\n",
    "print(f'Rows with complete Price, Quantity, and Total Spent: {len(completeData)}')\n",
    "\n",
    "# Calculate expected Total Spent using the formula\n",
    "completeData['Calculated Total'] = completeData['Price Per Unit'] * completeData['Quantity']\n",
    "\n",
    "# Calculate absolute difference between actual and calculated\n",
    "completeData['Difference'] = abs(completeData['Total Spent'] - completeData['Calculated Total'])\n",
    "\n",
    "# Count rows with significant differences (> 0.01 to account for floating point precision)\n",
    "inconsistent = (completeData['Difference'] > 0.01).sum()\n",
    "\n",
    "print(f'Rows with mathematical inconsistency (diff > 0.01): {inconsistent}')\n",
    "\n"
   ],
   "id": "de0ac09281bf23ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with complete Price, Quantity, and Total Spent: 11362\n",
      "Rows with mathematical inconsistency (diff > 0.01): 0\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Impact on remaining missing values\n",
    "\n",
    "Analyze how deletion of Total Spent missing rows affects the overall missing data landscape, particularly for `Item` and `Price Per Unit` which will be handled in subsequent steps.\n"
   ],
   "id": "8232e7d22274f43a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:49.721020Z",
     "start_time": "2025-10-06T19:56:49.714833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count missing Item values before and after deletion\n",
    "itemMissingBefore = df[ITEM].isna().sum()\n",
    "itemMissingAfter = dataCleaned[ITEM].isna().sum()\n",
    "itemRemoved = itemMissingBefore - itemMissingAfter\n",
    "itemRemovedPct = (itemRemoved / itemMissingBefore * 100) if itemMissingBefore else 0\n",
    "\n",
    "print(f'Item missing before: {itemMissingBefore}')\n",
    "print(f'Item missing after: {itemMissingAfter}')\n",
    "print(f'Item missing rows removed: {itemRemoved} ({itemRemovedPct:.1f}% of Item missing cases)')\n",
    "print(f'Item missing rows remaining: {itemMissingAfter} ({(itemMissingAfter / itemMissingBefore * 100) if itemMissingBefore else 0:.1f}%)')\n",
    "\n",
    "print('\\nImpact on Price Per Unit missingness:')\n",
    "print('=' * 80)\n",
    "# Count missing Price Per Unit values before and after deletion\n",
    "priceMissingBefore = df[PRICE_PER_UNIT].isna().sum()\n",
    "priceMissingAfter = dataCleaned[PRICE_PER_UNIT].isna().sum()\n",
    "priceRemoved = priceMissingBefore - priceMissingAfter\n",
    "priceRemovedPct = (priceRemoved / priceMissingBefore * 100) if priceMissingBefore else 0\n",
    "\n",
    "print(f'Price Per Unit missing before: {priceMissingBefore}')\n",
    "print(f'Price Per Unit missing after: {priceMissingAfter}')\n"
   ],
   "id": "b5807da61c0244d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item missing before: 1213\n",
      "Item missing after: 609\n",
      "Item missing rows removed: 604 (49.8% of Item missing cases)\n",
      "Item missing rows remaining: 609 (50.2%)\n",
      "\n",
      "Impact on Price Per Unit missingness:\n",
      "================================================================================\n",
      "Price Per Unit missing before: 609\n",
      "Price Per Unit missing after: 609\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Persist results\n",
    "\n",
    "Save the cleaned dataset with Total Spent missing rows removed. This becomes the input for subsequent imputation steps (Price Per Unit, then Item).\n"
   ],
   "id": "5ab3146aecfbb462"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:56:51.013866Z",
     "start_time": "2025-10-06T19:56:50.982248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save cleaned dataset to CSV\n",
    "dataCleaned.to_csv(CSV_OUT, index=False)\n"
   ],
   "id": "9dbc3d2faf4c0687",
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "02533bdf",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "**Total Spent Handling**\n",
    "\n",
    "**Classification:** MAR (Missing At Random)\n",
    "- Missingness depends on Item field (observable variable)\n",
    "- Perfect co-missingness with Quantity (100% overlap)\n",
    "\n",
    "**Method:** Listwise deletion\n",
    "- Removed 604 rows (4.8% of dataset)\n",
    "- Retained 95.2% of data\n",
    "\n",
    "**Justification:**\n",
    "- Total Spent is a critical target variable that should not be estimated\n",
    "- Cannot reconstruct: all missing cases also lack Quantity\n",
    "- Small data loss with large gain in data integrity\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c8e21123fdad76a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
