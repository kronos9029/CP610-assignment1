{
 "cells": [
  {
   "cell_type": "code",
   "id": "835a7c8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:47:55.728853Z",
     "start_time": "2025-10-06T19:47:55.727539Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "d9f5d8d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:47:56.095204Z",
     "start_time": "2025-10-06T19:47:56.092204Z"
    }
   },
   "source": "# Input file after dropping rows with missing Total Spent\nCSV_IN = \"../../output/1_handle_missing_data/total_spent_cleaned.csv\"\nCSV_OUT = \"../../output/1_handle_missing_data/price_per_unit_reconstructed.csv\"\n# Define columns name\nTOTAL_SPENT = \"Total Spent\"\nPRICE_PER_UNIT = \"Price Per Unit\"\nQUANTITY = \"Quantity\"\nCATEGORY = \"Category\"\nPAYMENT_METHOD = \"Payment Method\"\nLOCATION = \"Location\"\nITEM = \"Item\"\nTRANSACTION_ID = \"Transaction ID\"\n\n# Define error\nCOERCE_ERRORS = \"coerce\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "395e5a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T19:47:56.791438Z",
     "start_time": "2025-10-06T19:47:56.772169Z"
    }
   },
   "source": [
    "df = pd.read_csv(CSV_IN)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "6ae57090",
   "metadata": {},
   "source": [
    "### Quantify missing Price Per Unit\n",
    "\n",
    "Determine the scale of missing entries in `Price Per Unit` after STEP 1 deletion. Assess whether deterministic reconstruction using the formula `Price = Total Spent ÷ Quantity` is feasible.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert column's values to numeric, coercing errors to NaN\n",
    "# col is each of the relevant columns\n",
    "for col in [PRICE_PER_UNIT, QUANTITY, TOTAL_SPENT]:\n",
    "    # pd.to_numeric converts values in col to numeric, with errors coerced to NaN\n",
    "    # df[col] accesses the target column\n",
    "    # errors=COERCE_ERRORS specifies that parsing errors are set to NaN\n",
    "    df[col] = pd.to_numeric(df[col], errors = COERCE_ERRORS)\n",
    "\n",
    "# Count missing Price Per Unit values\n",
    "missingPrice = df[PRICE_PER_UNIT].isna()\n",
    "print(f'Missing Price Per Unit rows: {missingPrice.sum()} of {len(df)} ({missingPrice.mean():.2%})')\n",
    "\n",
    "# Verify that Total Spent and Quantity are complete (from STEP 1)\n",
    "print(f'\\nTotal Spent missing: {df[TOTAL_SPENT].isna().sum()}')\n",
    "print(f'Quantity missing: {df[QUANTITY].isna().sum()}')\n"
   ],
   "id": "76c93746848b0611"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Missingness mechanism\n",
    "\n",
    "Quantifying how often `Price Per Unit` is missing within each `Category`, payment method, and location to understand if the pattern is random or systematic. This helps confirm the MAR classification from the overall analysis.\n"
   ],
   "id": "587095aad3571570"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Analyze missingness patterns across categories\n",
    "summary = df.assign(missingPrice=missingPrice).groupby(CATEGORY)['missingPrice'].mean().sort_values(ascending=False) * 100\n",
    "print('Share of Price Per Unit missing by Category %:')\n",
    "print(summary.round(2))\n",
    "\n",
    "# Analyze missingness patterns across payment methods\n",
    "paymentShare = df.assign(missingPrice=missingPrice).groupby(PAYMENT_METHOD)['missingPrice'].mean().sort_values(ascending=False) * 100\n",
    "print('\\nShare of Price Per Unit missing by Payment Method %:')\n",
    "print(paymentShare.round(2))\n",
    "\n",
    "# Analyze missingness patterns across locations\n",
    "locationShare = df.assign(missingPrice=missingPrice).groupby(LOCATION)['missingPrice'].mean().sort_values(ascending=False) * 100\n",
    "print('\\nShare of Price Per Unit missing by Location %:')\n",
    "print(locationShare.round(2))\n"
   ],
   "id": "2526ecdc9ed9665f"
  },
  {
   "cell_type": "markdown",
   "id": "356e72b7",
   "metadata": {},
   "source": [
    "### Co-missingness analysis\n",
    "\n",
    "Examining whether `Price Per Unit` is missing alongside other key fields, particularly `Item`. This helps confirm the systematic pattern identified in the overall analysis.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check co-missingness with Item\n",
    "# missingPrice & df['Item'].isna() creates boolean Series that is True only when BOTH are missing\n",
    "# .sum() counts how many rows have both fields missing\n",
    "# Perfect overlap would mean all missing Price Per Unit also have missing Item\n",
    "itemOverlap = (missingPrice & df[ITEM].isna()).sum()\n",
    "print(f'Rows with both Price Per Unit and Item missing: {itemOverlap}')\n",
    "print(f'Price Per Unit missing: {missingPrice.sum()}')\n",
    "\n",
    "# Check co-missingness with Total Spent\n",
    "# Count rows where both Price Per Unit and Total Spent are missing\n",
    "totalOverlap = (missingPrice & df[TOTAL_SPENT].isna()).sum()\n",
    "print(f'\\nRows with both Price Per Unit and Total Spent missing: {totalOverlap}')\n",
    "\n",
    "# Check co-missingness with Quantity\n",
    "# Count rows where both Price Per Unit and Quantity are missing\n",
    "qtyOverlap = (missingPrice & df[QUANTITY].isna()).sum()\n",
    "print(f'Rows with both Price Per Unit and Quantity missing: {qtyOverlap}')\n"
   ],
   "id": "869ac8e4c185f708"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reconstructability assessment\n",
    "\n",
    "Since `Price Per Unit = Total Spent ÷ Quantity`, assess how many missing `Price Per Unit` values can be deterministically reconstructed. After STEP 1, both Total Spent and Quantity are guaranteed to be complete, making 100% reconstruction possible.\n"
   ],
   "id": "e73ef23f51883a24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check if Price Per Unit can be reconstructed from Total Spent and Quantity\n",
    "reconstructable = missingPrice & df[TOTAL_SPENT].notna() & df[QUANTITY].notna()\n",
    "reconstructableCount = reconstructable.sum()\n",
    "\n",
    "print(f'Missing Price Per Unit that CAN be reconstructed: {reconstructableCount} out of {missingPrice.sum()}')\n",
    "\n",
    "# Check for any cases where Quantity is zero (division by zero issue)\n",
    "zeroQty = missingPrice & (df[QUANTITY] == 0)\n",
    "zeroQtyCount = zeroQty.sum()\n",
    "\n",
    "print(zeroQtyCount)\n"
   ],
   "id": "5e2e8e0df5b923b"
  },
  {
   "cell_type": "markdown",
   "id": "b74ffb8b",
   "metadata": {},
   "source": [
    "### Missing data classification\n",
    "\n",
    "**Classification: MAR (Missing At Random)**\n",
    "\n",
    "**Rationale:**\n",
    "- **Perfect overlap with Item field:** All 609 missing Price Per Unit values occur when Item is also missing (100% co-missingness)\n",
    "- Missing rates vary by category (4.09%-5.56%), with Milk Products showing the highest rate\n",
    "- The missingness depends on the Item field (an observable variable)\n",
    "- Not MCAR because missing rates are not uniform across categories\n",
    "- Not MNAR because the missingness is explained by the Item field status, not by the price values themselves\n",
    "\n",
    "**Key finding:** When `Item` was not recorded during data collection, `Price Per Unit` was also systematically omitted. However, since both `Total Spent` and `Quantity` are present, we can deterministically reconstruct all missing prices with zero estimation error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f33d4e",
   "metadata": {},
   "source": [
    "### Handling strategy: Deterministic imputation\n",
    "\n",
    "**Justification for formula-based reconstruction (not statistical imputation):**\n",
    "\n",
    "1. **Mathematical relationship exists:** `Price Per Unit = Total Spent ÷ Quantity` is a known, exact formula\n",
    "2. **Zero estimation error:** This is not imputation—it's reconstruction of a calculable value\n",
    "3. **100% reconstructable:** All 609 missing prices can be calculated exactly (both Total and Quantity present)\n",
    "4. **Maintains data integrity:** The reconstructed values perfectly satisfy the mathematical relationship\n",
    "5. **Best practice:** When deterministic relationships exist, always use them before statistical methods\n",
    "\n",
    "**Why not statistical imputation:**\n",
    "- No need for mean/median/mode imputation when exact values can be calculated\n",
    "- Statistical methods introduce estimation error; formula-based reconstruction has zero error\n",
    "- Maintains perfect mathematical consistency across the dataset\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display sample of rows to be imputed\n",
    "\n",
    "print(df[missingPrice][[TRANSACTION_ID, CATEGORY, ITEM, PRICE_PER_UNIT, QUANTITY, TOTAL_SPENT]].head(10))\n"
   ],
   "id": "560f1e61d0a02fa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Count missing values before imputation\n",
    "priceMissingBefore = missingPrice.sum()\n",
    "print(f'Price Per Unit missing before reconstruction: {priceMissingBefore}')\n",
    "\n",
    "# Perform deterministic imputation using the mathematical formula\n",
    "# Create a filter for rows where Price Per Unit is missing\n",
    "df.loc[missingPrice, PRICE_PER_UNIT] = df.loc[missingPrice, TOTAL_SPENT] / df.loc[missingPrice, QUANTITY]\n",
    "\n",
    "# Count missing values after imputation\n",
    "priceMissingAfter = df[PRICE_PER_UNIT].isna().sum()\n",
    "# Calculate how many values were successfully reconstructed\n",
    "valuesReconstructed = priceMissingBefore - priceMissingAfter\n",
    "\n",
    "print(f'Price Per Unit missing after reconstruction: {priceMissingAfter}')\n",
    "print(f'Values successfully reconstructed: {valuesReconstructed}')\n"
   ],
   "id": "a20c564c81e1b729"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Validation: Verify reconstruction accuracy\n",
    "\n",
    "Verify that the reconstructed Price Per Unit values are correct by checking mathematical consistency across ALL rows (both originally complete and newly reconstructed).\n"
   ],
   "id": "d5325c3e8ee9819d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Verify Price Per Unit is now complete\n",
    "print(f'{PRICE_PER_UNIT} missing: {df[PRICE_PER_UNIT].isna().sum()}')\n",
    "print(f'{TOTAL_SPENT} missing: {df[TOTAL_SPENT].isna().sum()}')\n",
    "print(f'{QUANTITY} missing: {df[QUANTITY].isna().sum()}')\n"
   ],
   "id": "dcb154112fa112b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sample inspection: Before and after reconstruction\n",
    "\n",
    "Display sample rows that were reconstructed to verify the calculation worked correctly.\n"
   ],
   "id": "f8e719a08887e557"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:01:28.628422Z",
     "start_time": "2025-10-06T20:01:28.621354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display sample of reconstructed rows\n",
    "print(df[missingPrice][[TRANSACTION_ID, CATEGORY, ITEM, PRICE_PER_UNIT, QUANTITY, TOTAL_SPENT]].head(10))\n",
    "\n",
    "print('\\nVerification:')\n",
    "sampleData = df[missingPrice].head(5)\n",
    "print(sampleData)\n"
   ],
   "id": "fcbf23e8e42b5264",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Transaction ID                            Category Item  Price Per Unit  \\\n",
      "12     TXN_1007496                            Butchers  NaN            15.5   \n",
      "50     TXN_1032287                                Food  NaN            21.5   \n",
      "68     TXN_1044590       Electric household essentials  NaN            14.0   \n",
      "70     TXN_1046262                       Milk Products  NaN            14.0   \n",
      "71     TXN_1046367  Computers and electric accessories  NaN            18.5   \n",
      "76     TXN_1051223                          Patisserie  NaN             5.0   \n",
      "87     TXN_1058643                                Food  NaN             9.5   \n",
      "104    TXN_1071762                           Beverages  NaN             9.5   \n",
      "134    TXN_1095879                           Beverages  NaN             6.5   \n",
      "136    TXN_1096977                                Food  NaN            23.0   \n",
      "\n",
      "     Quantity  Total Spent  \n",
      "12       10.0        155.0  \n",
      "50        2.0         43.0  \n",
      "68        4.0         56.0  \n",
      "70        5.0         70.0  \n",
      "71       10.0        185.0  \n",
      "76        9.0         45.0  \n",
      "87        2.0         19.0  \n",
      "104       3.0         28.5  \n",
      "134      10.0         65.0  \n",
      "136       9.0        207.0  \n",
      "\n",
      "Verification:\n",
      "   Transaction ID Customer ID                            Category Item  \\\n",
      "12    TXN_1007496     CUST_01                            Butchers  NaN   \n",
      "50    TXN_1032287     CUST_16                                Food  NaN   \n",
      "68    TXN_1044590     CUST_12       Electric household essentials  NaN   \n",
      "70    TXN_1046262     CUST_14                       Milk Products  NaN   \n",
      "71    TXN_1046367     CUST_21  Computers and electric accessories  NaN   \n",
      "\n",
      "    Price Per Unit  Quantity  Total Spent Payment Method  Location  \\\n",
      "12            15.5      10.0        155.0    Credit Card    Online   \n",
      "50            21.5       2.0         43.0           Cash    Online   \n",
      "68            14.0       4.0         56.0           Cash    Online   \n",
      "70            14.0       5.0         70.0           Cash  In-store   \n",
      "71            18.5      10.0        185.0           Cash  In-store   \n",
      "\n",
      "   Transaction Date Discount Applied  \n",
      "12       2024-02-05             True  \n",
      "50       2022-07-27              NaN  \n",
      "68       2024-05-07            False  \n",
      "70       2022-11-19            False  \n",
      "71       2022-06-21              NaN  \n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Impact on remaining missing values\n",
    "\n",
    "Analyze the current state of missing data after Price Per Unit reconstruction. Only `Item` should have missing values remaining (609 rows).\n"
   ],
   "id": "5bf3c7ca2bb1bfa0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:01:54.694777Z",
     "start_time": "2025-10-06T20:01:54.687083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Current missing value status across all columns:')\n",
    "\n",
    "missingSummary = df.isnull().sum()\n",
    "missingCols = missingSummary[missingSummary > 0]\n",
    "\n",
    "print(missingCols)\n"
   ],
   "id": "a44facd2e16a45e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current missing value status across all columns:\n",
      "Item                 609\n",
      "Discount Applied    3988\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Persist results\n",
    "\n",
    "Save the dataset with Price Per Unit reconstructed. This becomes the input for STEP 3 (Item imputation).\n"
   ],
   "id": "1f5f008610fc24d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save dataset with Price Per Unit reconstructed to CSV\n",
    "\n",
    "df.to_csv(CSV_OUT, index=False)\n"
   ],
   "id": "f1156f44acd892bf"
  },
  {
   "cell_type": "markdown",
   "id": "3f04e19f",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "**Price Per Unit Handling**\n",
    "\n",
    "**Classification:** MAR (Missing At Random)\n",
    "- Missingness depends on Item field (observable variable)\n",
    "- Perfect co-missingness with Item (100% overlap)\n",
    "- Missing rates vary by category (4.09%-5.56%)\n",
    "\n",
    "**Method:** Deterministic reconstruction using formula\n",
    "- Formula: `Price Per Unit = Total Spent ÷ Quantity`\n",
    "- Reconstructed 609 values (100% of missing prices)\n",
    "- Zero estimation error\n",
    "\n",
    "**Validation results:**\n",
    "- All 609 missing prices successfully reconstructed\n",
    "- 100% mathematical consistency: Total = Price × Quantity\n",
    "- Zero reconstruction errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6702a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
