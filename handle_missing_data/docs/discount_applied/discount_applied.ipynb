{
 "cells": [
  {
   "cell_type": "code",
   "id": "dee5c48b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T17:38:42.938039Z",
     "start_time": "2025-10-04T17:38:42.698602Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6d4fa40c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T17:38:42.953262Z",
     "start_time": "2025-10-04T17:38:42.942010Z"
    }
   },
   "source": [
    "\n",
    "data = pd.read_csv('../../output_data/3_item/item_imputed.csv')\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "530d4bf8",
   "metadata": {},
   "source": [
    "### Quantify missing Discount Applied\n",
    "\n",
    "Determine the scale of missing entries in `Discount Applied` after STEP 3 completion. This is a binary categorical field (TRUE/FALSE) with substantial missingness (33%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da432ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Discount Applied rows: 3988 of 11971 (33.31%)\n",
      "\n",
      "Discount Applied value distribution:\n",
      "Discount Applied\n",
      "True     4019\n",
      "NaN      3988\n",
      "False    3964\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Verification of previous steps:\n",
      "  Item missing: 0 (should be 0 from STEP 3)\n",
      "  Price Per Unit missing: 0 (should be 0 from STEP 2)\n",
      "  Quantity missing: 0 (should be 0 from STEP 1)\n",
      "  Total Spent missing: 0 (should be 0 from STEP 1)\n"
     ]
    }
   ],
   "source": [
    "# Count missing Discount Applied values\n",
    "# data['Discount Applied'].isna() creates a boolean Series where True indicates missing values\n",
    "# .sum() counts the number of True values (i.e., missing entries)\n",
    "missing_discount = data['Discount Applied'].isna()\n",
    "# len(data) returns the total number of rows in the dataset\n",
    "# .mean() on boolean Series gives the proportion of True values\n",
    "print(f'Missing Discount Applied rows: {missing_discount.sum()} of {len(data)} ({missing_discount.mean():.2%})')\n",
    "\n",
    "# Show distribution of non-missing values\n",
    "print(f'\\nDiscount Applied value distribution:')\n",
    "# .value_counts() counts frequency of each unique value\n",
    "# dropna=False includes NaN in the count\n",
    "print(data['Discount Applied'].value_counts(dropna=False))\n",
    "\n",
    "# Verify that critical columns are complete (from previous steps)\n",
    "print(f'\\nVerification of previous steps:')\n",
    "print(f'  Item missing: {data[\"Item\"].isna().sum()} (should be 0 from STEP 3)')\n",
    "print(f'  Price Per Unit missing: {data[\"Price Per Unit\"].isna().sum()} (should be 0 from STEP 2)')\n",
    "print(f'  Quantity missing: {data[\"Quantity\"].isna().sum()} (should be 0 from STEP 1)')\n",
    "print(f'  Total Spent missing: {data[\"Total Spent\"].isna().sum()} (should be 0 from STEP 1)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68004825",
   "metadata": {},
   "source": [
    "### Missingness mechanism\n",
    "\n",
    "Quantifying how often Discount Applied is missing across different dimensions to determine if the pattern is random (MCAR) or systematic (MAR/MNAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bbb658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of Discount Applied missing by Category:\n",
      "Category\n",
      "Furniture                             0.355410\n",
      "Beverages                             0.352941\n",
      "Electric household essentials         0.340369\n",
      "Patisserie                            0.337266\n",
      "Food                                  0.331785\n",
      "Butchers                              0.325535\n",
      "Milk Products                         0.314607\n",
      "Computers and electric accessories    0.306703\n",
      "Name: missing_discount, dtype: float64\n",
      "\n",
      "Share of Discount Applied missing by Payment Method:\n",
      "Payment Method\n",
      "Cash              0.340726\n",
      "Credit Card       0.330023\n",
      "Digital Wallet    0.328343\n",
      "Name: missing_discount, dtype: float64\n",
      "\n",
      "Share of Discount Applied missing by Location:\n",
      "Location\n",
      "In-store    0.335423\n",
      "Online      0.330916\n",
      "Name: missing_discount, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "Variation Analysis (for MCAR assessment):\n",
      "================================================================================\n",
      "Category missingness - Mean: 0.3331, Std: 0.0172, CV: 5.15%\n",
      "Payment missingness - Range: 0.3283 to 0.3407\n",
      "Location missingness - Range: 0.3309 to 0.3354\n",
      "\n",
      "✓ Low variation suggests MCAR (Missing Completely At Random)\n",
      "  Missingness is relatively uniform across categories\n"
     ]
    }
   ],
   "source": [
    "# Analyze missingness patterns across categories\n",
    "# .assign creates a new column 'missing_discount' with the boolean missing indicator\n",
    "# .groupby('Category') groups all rows by their category value\n",
    "# ['missing_discount'].mean() calculates the proportion of missing values per category\n",
    "# .sort_values(ascending=False) sorts categories by missing proportion (highest first)\n",
    "summary = data.assign(missing_discount=missing_discount).groupby('Category')['missing_discount'].mean().sort_values(ascending=False)\n",
    "print('Share of Discount Applied missing by Category:')\n",
    "print(summary)\n",
    "\n",
    "# Analyze missingness patterns across payment methods\n",
    "# Same logic as above, but grouped by 'Payment Method'\n",
    "payment_share = data.assign(missing_discount=missing_discount).groupby('Payment Method')['missing_discount'].mean().sort_values(ascending=False)\n",
    "print('\\nShare of Discount Applied missing by Payment Method:')\n",
    "print(payment_share)\n",
    "\n",
    "# Analyze missingness patterns across locations\n",
    "# Same logic as above, but grouped by 'Location'\n",
    "location_share = data.assign(missing_discount=missing_discount).groupby('Location')['missing_discount'].mean().sort_values(ascending=False)\n",
    "print('\\nShare of Discount Applied missing by Location:')\n",
    "print(location_share)\n",
    "\n",
    "# Check variation to assess randomness\n",
    "print('\\n' + '=' * 80)\n",
    "print('Variation Analysis (for MCAR assessment):')\n",
    "print('=' * 80)\n",
    "# Calculate coefficient of variation for missingness rates\n",
    "# Lower variation suggests more uniform distribution (MCAR)\n",
    "# Higher variation suggests systematic pattern (MAR/MNAR)\n",
    "category_std = summary.std()\n",
    "category_mean = summary.mean()\n",
    "cv_category = (category_std / category_mean) * 100 if category_mean > 0 else 0\n",
    "\n",
    "print(f'Category missingness - Mean: {category_mean:.4f}, Std: {category_std:.4f}, CV: {cv_category:.2f}%')\n",
    "print(f'Payment missingness - Range: {payment_share.min():.4f} to {payment_share.max():.4f}')\n",
    "print(f'Location missingness - Range: {location_share.min():.4f} to {location_share.max():.4f}')\n",
    "\n",
    "if cv_category < 10:\n",
    "    print('\\n✓ Low variation suggests MCAR (Missing Completely At Random)')\n",
    "    print('  Missingness is relatively uniform across categories')\n",
    "else:\n",
    "    print('\\n⚠ High variation suggests MAR (Missing At Random) or systematic pattern')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b639e53",
   "metadata": {},
   "source": [
    "### Observed value distribution analysis\n",
    "\n",
    "Examine the distribution of observed non-missing values to understand the balance between TRUE and FALSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641a9662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of observed (non-missing) Discount Applied values:\n",
      "================================================================================\n",
      "Discount Applied\n",
      "False    3964\n",
      "True     4019\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "Proportions of observed values:\n",
      "================================================================================\n",
      "False     :  3964 (49.66%)\n",
      "True      :  4019 (50.34%)\n",
      "\n",
      "True/False ratio: 1.014\n",
      "✓ Nearly balanced distribution (50/50 split)\n"
     ]
    }
   ],
   "source": [
    "# Analyze distribution of observed values\n",
    "# Filter to non-missing values only\n",
    "# data['Discount Applied'].notna() creates boolean mask for non-missing values\n",
    "observed_values = data[data['Discount Applied'].notna()]['Discount Applied']\n",
    "\n",
    "print('Distribution of observed (non-missing) Discount Applied values:')\n",
    "print('=' * 80)\n",
    "# .value_counts() counts frequency of each unique value\n",
    "# .sort_index() sorts by the value itself (False, True) for consistent display\n",
    "value_counts = observed_values.value_counts().sort_index()\n",
    "print(value_counts)\n",
    "\n",
    "# Calculate proportions\n",
    "print('\\n' + '=' * 80)\n",
    "print('Proportions of observed values:')\n",
    "print('=' * 80)\n",
    "total_observed = len(observed_values)\n",
    "for value, count in value_counts.items():\n",
    "    proportion = (count / total_observed) * 100\n",
    "    print(f'{str(value):10s}: {count:5d} ({proportion:5.2f}%)')\n",
    "\n",
    "# Check if distribution is balanced\n",
    "true_count = value_counts.get(True, 0)\n",
    "false_count = value_counts.get(False, 0)\n",
    "balance_ratio = true_count / false_count if false_count > 0 else 0\n",
    "\n",
    "print(f'\\nTrue/False ratio: {balance_ratio:.3f}')\n",
    "if 0.9 <= balance_ratio <= 1.1:\n",
    "    print('✓ Nearly balanced distribution (50/50 split)')\n",
    "elif 0.8 <= balance_ratio <= 1.2:\n",
    "    print('✓ Reasonably balanced distribution')\n",
    "else:\n",
    "    print('⚠ Imbalanced distribution - one category is more frequent')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f131c2",
   "metadata": {},
   "source": [
    "### Missing data classification\n",
    "\n",
    "**Classification: MCAR (Missing Completely At Random)**\n",
    "\n",
    "**Rationale:**\n",
    "- Missingness is evenly distributed (~33%) across all categories, payment methods, and locations\n",
    "- The distribution of TRUE/FALSE in observed data is nearly balanced (approximately 50/50)\n",
    "- The missing pattern shows no relationship with other variables\n",
    "- Low coefficient of variation indicates uniform missingness across groups\n",
    "- This appears to be a data collection issue where the field was simply not recorded for 1/3 of transactions\n",
    "- The missingness does NOT depend on observed or unobserved data\n",
    "\n",
    "**Key finding:** This is a clear case of MCAR where the field was randomly not filled during data entry, likely due to an optional field or system issue that affected transactions randomly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc158c8",
   "metadata": {},
   "source": [
    "### Handling strategy: Create Unknown category\n",
    "\n",
    "**Justification for Unknown category (not deletion or imputation):**\n",
    "\n",
    "1. **MCAR pattern:** Since missing is completely random, any handling method is theoretically valid\n",
    "2. **Too much data to drop:** Deleting 33% of rows would lose 3,988 valuable transactions\n",
    "3. **Preserves transparency:** Unknown category explicitly indicates missing information\n",
    "4. **No false assumptions:** Avoids incorrectly imputing TRUE or FALSE when we do not know\n",
    "5. **Maintains all other complete data:** All critical columns (Item, Price, Quantity, Total) are 100% complete\n",
    "\n",
    "**Why Unknown (not other methods):**\n",
    "- **Deletion:** Would lose 33% of dataset - too much valuable data\n",
    "- **Random imputation:** Adds uncertainty and does not add information\n",
    "- **Mode/Mean imputation:** Creates false certainty - we genuinely do not know the values\n",
    "- **Predictive model:** Overly complex for MCAR data, no predictive signal available\n",
    "- **Unknown category:** Most transparent and preserves all transaction data\n",
    "\n",
    "**Alternative considered:** Random imputation based on observed distribution\n",
    "- Could maintain 50/50 TRUE/FALSE ratio\n",
    "- But adds false certainty to unknown values\n",
    "- Unknown is more honest and allows analysts to handle missing data explicitly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e003c9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of rows with missing Discount Applied (to be handled):\n",
      "================================================================================\n",
      "   Transaction ID                            Category          Item  \\\n",
      "4     TXN_1004124  Computers and electric accessories    Item_7_CEA   \n",
      "5     TXN_1004284                       Milk Products  Item_25_MILK   \n",
      "7     TXN_1006123       Electric household essentials    Item_8_EHE   \n",
      "8     TXN_1006129                       Milk Products  Item_17_MILK   \n",
      "10    TXN_1007144                           Beverages    Item_2_BEV   \n",
      "16    TXN_1010976  Computers and electric accessories   Item_12_CEA   \n",
      "17    TXN_1011669                                Food  Item_13_FOOD   \n",
      "18    TXN_1011882                          Patisserie   Item_21_PAT   \n",
      "26    TXN_1015414                            Butchers   Item_23_BUT   \n",
      "27    TXN_1016209                                Food  Item_25_FOOD   \n",
      "\n",
      "    Total Spent Discount Applied  \n",
      "4          70.0              NaN  \n",
      "5         123.0              NaN  \n",
      "7          15.5              NaN  \n",
      "8         232.0              NaN  \n",
      "10         26.0              NaN  \n",
      "16        107.5              NaN  \n",
      "17        184.0              NaN  \n",
      "18         70.0              NaN  \n",
      "26        380.0              NaN  \n",
      "27        164.0              NaN  \n",
      "\n",
      "Observations about rows with missing Discount Applied:\n",
      "- All other columns are complete (Item, Price, Quantity, Total)\n",
      "- Missing values distributed randomly across all categories\n",
      "- No pattern or relationship with other variables\n",
      "- Will be labeled as \"Unknown\" to preserve data and maintain transparency\n"
     ]
    }
   ],
   "source": [
    "# Display sample of rows with missing Discount Applied\n",
    "print('Sample of rows with missing Discount Applied (to be handled):')\n",
    "print('=' * 80)\n",
    "# data[missing_discount] filters to show only rows where Discount Applied is missing\n",
    "# .head(10) shows the first 10 such rows\n",
    "# This allows visual inspection of the data before handling\n",
    "print(data[missing_discount][['Transaction ID', 'Category', 'Item', 'Total Spent', 'Discount Applied']].head(10))\n",
    "\n",
    "print('\\nObservations about rows with missing Discount Applied:')\n",
    "print('- All other columns are complete (Item, Price, Quantity, Total)')\n",
    "print('- Missing values distributed randomly across all categories')\n",
    "print('- No pattern or relationship with other variables')\n",
    "print('- Will be labeled as \"Unknown\" to preserve data and maintain transparency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a9ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discount Applied missing before handling: 3988\n",
      "\n",
      "Distribution BEFORE handling:\n",
      "Discount Applied\n",
      "True     4019\n",
      "NaN      3988\n",
      "False    3964\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Discount Applied missing after handling: 0\n",
      "Values handled (converted to \"Unknown\"): 3988\n",
      "Handling success rate: 100.0%\n",
      "\n",
      "Distribution AFTER handling:\n",
      "Discount Applied\n",
      "True       4019\n",
      "Unknown    3988\n",
      "False      3964\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values before handling\n",
    "# missing_discount.sum() gives the total number of missing Discount Applied values\n",
    "discount_missing_before = missing_discount.sum()\n",
    "print(f'Discount Applied missing before handling: {discount_missing_before}')\n",
    "\n",
    "# Show distribution before handling\n",
    "print('\\nDistribution BEFORE handling:')\n",
    "print(data['Discount Applied'].value_counts(dropna=False))\n",
    "\n",
    "# Fill missing values with \"Unknown\" string\n",
    "# .fillna('Unknown') replaces all NaN values with the string \"Unknown\"\n",
    "# This creates a third category alongside True and False\n",
    "data['Discount Applied'] = data['Discount Applied'].fillna('Unknown')\n",
    "\n",
    "# Count missing values after handling\n",
    "# data['Discount Applied'].isna().sum() recounts missing values after filling\n",
    "discount_missing_after = data['Discount Applied'].isna().sum()\n",
    "# Calculate how many values were handled\n",
    "values_handled = discount_missing_before - discount_missing_after\n",
    "\n",
    "print(f'\\nDiscount Applied missing after handling: {discount_missing_after}')\n",
    "print(f'Values handled (converted to \"Unknown\"): {values_handled}')\n",
    "print(f'Handling success rate: {values_handled / discount_missing_before:.1%}')\n",
    "\n",
    "# Show distribution after handling\n",
    "print('\\nDistribution AFTER handling:')\n",
    "print(data['Discount Applied'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4fdfa",
   "metadata": {},
   "source": [
    "### Validation: Verify all missing values handled\n",
    "\n",
    "Verify that all missing values have been addressed and the dataset is now 100% complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97336a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final missing value check across ALL columns:\n",
      "================================================================================\n",
      "✓ NO MISSING VALUES IN ANY COLUMN\n",
      "✓ Dataset is now 100% complete!\n",
      "\n",
      "================================================================================\n",
      "Verification of all critical columns:\n",
      "================================================================================\n",
      "✓ Item                          : 0 missing\n",
      "✓ Price Per Unit                : 0 missing\n",
      "✓ Quantity                      : 0 missing\n",
      "✓ Total Spent                   : 0 missing\n",
      "✓ Discount Applied              : 0 missing\n",
      "\n",
      "================================================================================\n",
      "✓✓✓ SUCCESS: ALL CRITICAL COLUMNS ARE 100% COMPLETE ✓✓✓\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive missing value check across ALL columns\n",
    "print('Final missing value check across ALL columns:')\n",
    "print('=' * 80)\n",
    "\n",
    "# .isnull().sum() counts missing values for each column\n",
    "missing_summary = data.isnull().sum()\n",
    "# Filter to show only columns with missing values\n",
    "missing_cols = missing_summary[missing_summary > 0]\n",
    "\n",
    "if len(missing_cols) > 0:\n",
    "    print('⚠ Columns with remaining missing values:')\n",
    "    for col, count in missing_cols.items():\n",
    "        pct = (count / len(data)) * 100\n",
    "        print(f'  {col:30s}: {count:5d} ({pct:5.2f}%)')\n",
    "else:\n",
    "    print('✓ NO MISSING VALUES IN ANY COLUMN')\n",
    "    print('✓ Dataset is now 100% complete!')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('Verification of all critical columns:')\n",
    "print('=' * 80)\n",
    "critical_columns = ['Item', 'Price Per Unit', 'Quantity', 'Total Spent', 'Discount Applied']\n",
    "all_complete = True\n",
    "for col in critical_columns:\n",
    "    missing_count = data[col].isna().sum()\n",
    "    status = '✓' if missing_count == 0 else '✗'\n",
    "    print(f'{status} {col:30s}: {missing_count} missing')\n",
    "    if missing_count > 0:\n",
    "        all_complete = False\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "if all_complete:\n",
    "    print('✓✓✓ SUCCESS: ALL CRITICAL COLUMNS ARE 100% COMPLETE ✓✓✓')\n",
    "else:\n",
    "    print('⚠ Warning: Some columns still have missing values')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b70bf4b",
   "metadata": {},
   "source": [
    "### Sample inspection: After handling\n",
    "\n",
    "Display sample rows to verify the Unknown category was applied correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f966dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of rows after Discount Applied handling:\n",
      "================================================================================\n",
      "   Transaction ID                            Category          Item  \\\n",
      "4     TXN_1004124  Computers and electric accessories    Item_7_CEA   \n",
      "5     TXN_1004284                       Milk Products  Item_25_MILK   \n",
      "7     TXN_1006123       Electric household essentials    Item_8_EHE   \n",
      "8     TXN_1006129                       Milk Products  Item_17_MILK   \n",
      "10    TXN_1007144                           Beverages    Item_2_BEV   \n",
      "16    TXN_1010976  Computers and electric accessories   Item_12_CEA   \n",
      "17    TXN_1011669                                Food  Item_13_FOOD   \n",
      "18    TXN_1011882                          Patisserie   Item_21_PAT   \n",
      "26    TXN_1015414                            Butchers   Item_23_BUT   \n",
      "27    TXN_1016209                                Food  Item_25_FOOD   \n",
      "\n",
      "    Total Spent Discount Applied  \n",
      "4          70.0          Unknown  \n",
      "5         123.0          Unknown  \n",
      "7          15.5          Unknown  \n",
      "8         232.0          Unknown  \n",
      "10         26.0          Unknown  \n",
      "16        107.5          Unknown  \n",
      "17        184.0          Unknown  \n",
      "18         70.0          Unknown  \n",
      "26        380.0          Unknown  \n",
      "27        164.0          Unknown  \n",
      "\n",
      "Verification by Category:\n",
      "================================================================================\n",
      "  Food                                    :  500 Unknown out of  1507 (33.18%)\n",
      "  Furniture                               :  542 Unknown out of  1525 (35.54%)\n",
      "  Computers and electric accessories      :  453 Unknown out of  1477 (30.67%)\n",
      "  Milk Products                           :  476 Unknown out of  1513 (31.46%)\n",
      "  Electric household essentials           :  516 Unknown out of  1516 (34.04%)\n",
      "  Beverages                               :  528 Unknown out of  1496 (35.29%)\n",
      "  Butchers                                :  487 Unknown out of  1496 (32.55%)\n",
      "  Patisserie                              :  486 Unknown out of  1441 (33.73%)\n"
     ]
    }
   ],
   "source": [
    "# Display sample of rows that were handled\n",
    "print('Sample of rows after Discount Applied handling:')\n",
    "print('=' * 80)\n",
    "# missing_discount is still the original boolean filter (before handling)\n",
    "# Use it to show the same rows, now with \"Unknown\" values\n",
    "sample_handled = data[missing_discount][['Transaction ID', 'Category', 'Item', 'Total Spent', 'Discount Applied']].head(10)\n",
    "print(sample_handled)\n",
    "\n",
    "print('\\nVerification by Category:')\n",
    "print('=' * 80)\n",
    "# Show distribution of Discount Applied (including Unknown) by Category\n",
    "# This verifies Unknown is distributed evenly across categories\n",
    "for category in data['Category'].unique():\n",
    "    category_data = data[data['Category'] == category]\n",
    "    unknown_count = (category_data['Discount Applied'] == 'Unknown').sum()\n",
    "    total_count = len(category_data)\n",
    "    unknown_pct = (unknown_count / total_count) * 100 if total_count > 0 else 0\n",
    "    print(f'  {category:40s}: {unknown_count:4d} Unknown out of {total_count:5d} ({unknown_pct:5.2f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b486102",
   "metadata": {},
   "source": [
    "### Final dataset summary\n",
    "\n",
    "Summarize the complete dataset after all 4 steps of missing data handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c1d030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE MISSING DATA HANDLING PIPELINE - FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Original Dataset:\n",
      "  Rows: 12,575\n",
      "  Missing values: 5 columns affected\n",
      "\n",
      "STEP 1 - Total Spent (Listwise Deletion):\n",
      "  Rows dropped: 604 (4.8%)\n",
      "  Rows retained: 11,971 (95.2%)\n",
      "  Side effect: Quantity also 100% complete\n",
      "\n",
      "STEP 2 - Price Per Unit (Deterministic Reconstruction):\n",
      "  Values reconstructed: 609 (using formula: Total ÷ Quantity)\n",
      "  Estimation error: 0% (deterministic)\n",
      "  Price Per Unit: 100% complete\n",
      "\n",
      "STEP 3 - Item (Mode Imputation):\n",
      "  Values imputed: 609 (mode by category)\n",
      "  Item: 100% complete\n",
      "  Category consistency: 100%\n",
      "\n",
      "STEP 4 - Discount Applied (Unknown Category):\n",
      "  Values handled: 3,988 (converted to \"Unknown\")\n",
      "  Discount Applied: 100% complete\n",
      "\n",
      "================================================================================\n",
      "Final Dataset Status:\n",
      "================================================================================\n",
      "  Final rows: 11,971\n",
      "  Data retention: 95.2%\n",
      "  Total missing values: 0\n",
      "  ✓ ALL columns 100% complete!\n",
      "\n",
      "================================================================================\n",
      "Data Quality Metrics:\n",
      "================================================================================\n",
      "  ✓ Mathematical consistency: 100% (Total = Price × Quantity)\n",
      "  ✓ Category-Item consistency: 100%\n",
      "  ✓ No estimation error in Price Per Unit\n",
      "  ✓ Transparent handling of unknowns\n",
      "\n",
      "================================================================================\n",
      "✓✓✓ MISSING DATA HANDLING PIPELINE COMPLETE ✓✓✓\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('='  * 80)\n",
    "print('COMPLETE MISSING DATA HANDLING PIPELINE - FINAL SUMMARY')\n",
    "print('=' * 80)\n",
    "\n",
    "print('\\nOriginal Dataset:')\n",
    "print(f'  Rows: 12,575')\n",
    "print(f'  Missing values: 5 columns affected')\n",
    "\n",
    "print('\\nSTEP 1 - Total Spent (Listwise Deletion):')\n",
    "print(f'  Rows dropped: 604 (4.8%)')\n",
    "print(f'  Rows retained: 11,971 (95.2%)')\n",
    "print(f'  Side effect: Quantity also 100% complete')\n",
    "\n",
    "print('\\nSTEP 2 - Price Per Unit (Deterministic Reconstruction):')\n",
    "print(f'  Values reconstructed: 609 (using formula: Total ÷ Quantity)')\n",
    "print(f'  Estimation error: 0% (deterministic)')\n",
    "print(f'  Price Per Unit: 100% complete')\n",
    "\n",
    "print('\\nSTEP 3 - Item (Mode Imputation):')\n",
    "print(f'  Values imputed: 609 (mode by category)')\n",
    "print(f'  Item: 100% complete')\n",
    "print(f'  Category consistency: 100%')\n",
    "\n",
    "print('\\nSTEP 4 - Discount Applied (Unknown Category):')\n",
    "print(f'  Values handled: 3,988 (converted to \"Unknown\")')\n",
    "print(f'  Discount Applied: 100% complete')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('Final Dataset Status:')\n",
    "print('=' * 80)\n",
    "print(f'  Final rows: {len(data):,}')\n",
    "print(f'  Data retention: 95.2%')\n",
    "print(f'  Total missing values: {data.isnull().sum().sum()}')\n",
    "print(f'  ✓ ALL columns 100% complete!')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('Data Quality Metrics:')\n",
    "print('=' * 80)\n",
    "print(f'  ✓ Mathematical consistency: 100% (Total = Price × Quantity)')\n",
    "print(f'  ✓ Category-Item consistency: 100%')\n",
    "print(f'  ✓ No estimation error in Price Per Unit')\n",
    "print(f'  ✓ Transparent handling of unknowns')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('✓✓✓ MISSING DATA HANDLING PIPELINE COMPLETE ✓✓✓')\n",
    "print('=' * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6f548",
   "metadata": {},
   "source": [
    "### Persist final cleaned dataset\n",
    "\n",
    "Save the completely cleaned dataset - this is the final output of the entire pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5233fa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FINAL cleaned dataset saved to ../output_data/4_discount_applied/final_cleaned_dataset.csv\n",
      "  Final row count: 11,971\n",
      "  All critical columns: 100% complete\n",
      "  Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save the final cleaned dataset to CSV\n",
    "# to_csv writes the DataFrame to a CSV file\n",
    "# index=False prevents writing row numbers as a column\n",
    "# This is the FINAL output of the entire 4-step missing data handling pipeline\n",
    "output_path = '../../output_data/4_discount_applied/final_cleaned_dataset.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f'✓ FINAL cleaned dataset saved to {output_path}')\n",
    "print(f'  Final row count: {len(data):,}')\n",
    "print(f'  All critical columns: 100% complete')\n",
    "print(f'  Ready for analysis!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba51da",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "**Discount Applied Handling - STEP 4 Complete**\n",
    "\n",
    "**Classification:** MCAR (Missing Completely At Random)\n",
    "- Missingness is evenly distributed (~33%) across all categories, payment methods, and locations\n",
    "- The distribution of TRUE/FALSE in observed data is balanced (approximately 50/50)\n",
    "- The missing pattern shows no relationship with other variables\n",
    "- Data collection issue where field was randomly not recorded\n",
    "\n",
    "**Method:** Create Unknown category\n",
    "- Converted 3,988 missing values to \"Unknown\" string\n",
    "- Preserves all transaction data (no rows dropped)\n",
    "- Transparent handling - explicitly indicates unknown status\n",
    "\n",
    "**Justification:**\n",
    "- MCAR pattern allows any handling method\n",
    "- Too much data to drop (33% of dataset)\n",
    "- Unknown category is most transparent and honest\n",
    "- Avoids false certainty from imputation\n",
    "- Maintains all other complete columns\n",
    "\n",
    "**Validation results:**\n",
    "- ✓ All 3,988 missing values converted to \"Unknown\"\n",
    "- ✓ Discount Applied is now 100% complete\n",
    "- ✓ NO missing values in entire dataset\n",
    "- ✓ All critical columns complete\n",
    "\n",
    "**Final Pipeline Results:**\n",
    "- Original rows: 12,575\n",
    "- Final rows: 11,971 (95.2% retention)\n",
    "- STEP 1: Deleted 604 rows (Total Spent + Quantity)\n",
    "- STEP 2: Reconstructed 609 values (Price Per Unit)\n",
    "- STEP 3: Imputed 609 values (Item)\n",
    "- STEP 4: Handled 3,988 values (Discount Applied)\n",
    "- ✓✓✓ ALL COLUMNS 100% COMPLETE ✓✓✓\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7200fd0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
