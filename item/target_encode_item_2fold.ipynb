{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2-Fold Target Encoding — **Item** (Out-of-Fold) based on *Total Spent*\n",
        "\n",
        "Performs **2-Fold Target Encoding** for the **Item** column using **Total Spent** as the target.\n",
        "\n",
        "> **Pipeline position:** Run this after Customer ID encoding.  \n",
        "> **Input:** `encoded_customer_id_dataset.csv`  \n",
        "> **Outputs:**  \n",
        "> - Encoded dataset: `encoded_item_dataset.csv` (adds `Item Target Encoded`)  \n",
        "> - Final mapping (fit on full data): `item_target_encoding_mapping_2fold.csv` (for applying to external/test data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Setup: libraries & file names ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Input/Output files\n",
        "CSV_IN = Path(\"../encoded_output_data/1_customer_id/encoded_customer_id_dataset.csv\")\n",
        "CSV_OUT = Path(\"../encoded_output_data/2_item/encoded_item_dataset.csv\")\n",
        "\n",
        "# Columns\n",
        "ITEM        = \"Item\"\n",
        "TARGET_COL  = \"Total Spent\"\n",
        "ENCODED_COL = \"Item Target Encoded\"\n",
        "\n",
        "# 2-Fold parameters\n",
        "nSplits = 2          # fixed to 2-fold\n",
        "randomState = 42     # random seed for reproducibility\n",
        "shuffle = True       # shuffle before split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "79275534",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv(CSV_IN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 11971, Cols: 12\n",
            "\n",
            "Nulls in key columns:\n",
            "Item           0\n",
            "Total Spent    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Ensure target is numeric\n",
        "# .to_numeric with errors=\"coerce\" will convert non-numeric to NaN\n",
        "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors=\"coerce\")\n",
        "\n",
        "# row/col count & null summary\n",
        "rowCount, colCount = df.shape\n",
        "nullSummary = df[[ITEM, TARGET_COL]].isnull().sum()\n",
        "\n",
        "# print basic info\n",
        "print(f\"Rows: {rowCount}, Cols: {colCount}\")\n",
        "print(\"\\nNulls in key columns:\")\n",
        "print(nullSummary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why 2-Fold target encoding for *Item*?\n",
        "- **Item** is a **predictive category**: \n",
        "  + Some items are associated with higher/lower `Total Spent`.\n",
        "  + Machine Learning model will rely on it heavily. We must be stricter about avoiding leakage.\n",
        "- 2-Fold OOF encoding avoids self-leakage while remaining **simple and fast**.\n",
        "\n",
        "### Method (2-Fold OOF)\n",
        "Split data into two folds: **A** and **B**.  \n",
        "- Encode **A** using per-Item means computed **only from B**.  \n",
        "- Encode **B** using per-Item means computed **only from A**.  \n",
        "- Items unseen in the opposite fold → use **global mean**.\n",
        "Finally, fit per-Item means on the **full dataset** and save the mapping for test-time usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: opposite(train)=5985 encode(val)=5986 | unique Items in opposite=200\n",
            "Fold 2: opposite(train)=5986 encode(val)=5985 | unique Items in opposite=200\n",
            "\n",
            "Encoded summary:\n",
            "count    11971.000000\n",
            "mean       129.839852\n",
            "std         59.113998\n",
            "min         22.500000\n",
            "25%         79.613636\n",
            "50%        132.650943\n",
            "75%        176.433333\n",
            "max        335.750000\n",
            "Name: Item Target Encoded, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 2-Fold target encoding\n",
        "# Initialize KFold with 2 splits, shuffling, and a random state for reproducibility\n",
        "kf = KFold(n_splits=nSplits, shuffle=shuffle, random_state=randomState)\n",
        "\n",
        "# Calculate global mean of the target\n",
        "globalMean = df[TARGET_COL].mean()\n",
        "# Prepare a Series to hold the encoded values with the same index as df\n",
        "encoded = pd.Series(index=df.index, dtype=float)\n",
        "\n",
        "# Perform 2-Fold target encoding\n",
        "# fold variables: train_idx, val_idx\n",
        "# start=1 to make fold count human-friendly (1, 2, ...)\n",
        "# kf.split separates df into training and validation fold\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(df), start=1):\n",
        "    # For 2-fold: 'train_idx' is the opposite fold used to compute means, 'val_idx' is the fold we encode\n",
        "    train = df.iloc[train_idx] # opposite fold\n",
        "    val   = df.iloc[val_idx]  # current fold to encode\n",
        "    means = train.groupby(ITEM)[TARGET_COL].mean() # Calculate mean target per Item in training fold\n",
        "    encodedValues = val[ITEM].map(means).fillna(globalMean) # Map means to validation fold, fill NaN with global mean\n",
        "    encoded.iloc[val_idx] = encodedValues.values # Assign encoded values to the correct positions in the encoded Series\n",
        "    # Diagnostics\n",
        "    print(f\"Fold {fold}: opposite(train)={len(train_idx)} encode(val)={len(val_idx)} | unique Items in opposite={means.index.nunique()}\")\n",
        "\n",
        "# Attach encoded feature\n",
        "df[ENCODED_COL] = encoded\n",
        "\n",
        "# Diagnostics\n",
        "print(\"\\nEncoded summary:\")\n",
        "print(df[ENCODED_COL].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved encoded dataset: D:\\CP610\\encoded_output_data\\2_item\\encoded_item_dataset.csv\n",
            "New column: Item Target Encoded  |  Global mean fallback = 129.652577\n"
          ]
        }
      ],
      "source": [
        "# Save encoded dataset\n",
        "df.to_csv(CSV_OUT, index=False)\n",
        "print(f\"Saved encoded dataset: {CSV_OUT.resolve()}\")\n",
        "print(f\"New column: {ENCODED_COL}  |  Global mean fallback = {df[TARGET_COL].mean():.6f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
